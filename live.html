<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Video with Captions and Translation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        video {
            border: 2px solid #333;
            border-radius: 10px;
            width: 640px;
            height: 480px;
            margin-bottom: 20px;
        }
        #captions, #translated {
            margin-top: 10px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            width: 400px;
            text-align: center;
        }
        button {
            margin-top: 20px;
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }
    </style>
</head>
<body>

    <h1>Live Video with Captions and Translation</h1>


    <video id="video" autoplay playsinline></video>

    <div id="captions">Captions will appear here...</div>
    <div id="translated">Translated text will appear here...</div>

    <button id="startButton">Start Camera & Mic</button>
    <button id="stopButton" disabled>Stop Camera & Mic</button>

    <script>
        const video = document.getElementById('video');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const captionsDiv = document.getElementById('captions');
        const translatedDiv = document.getElementById('translated');

        let mediaStream;
        let recognition;

        if (!('webkitSpeechRecognition' in window)) {
            alert("Your browser does not support the Web Speech API. Please use Chrome.");
        } else {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
        }

        async function translateText(text, targetLanguage = 'es') {
    const apiKey = 'YOUR_GOOGLE_TRANSLATE_API_KEY';
    const url = `https://translation.googleapis.com/language/translate/v2?key=${apiKey}`;

    try {
        const response = await fetch(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                q: text,
                target: targetLanguage
            })
        });

        if (!response.ok) {
            const errorData = await response.json();
            console.error('Translation API error:', errorData);
            return 'Translation failed';
        }

        const data = await response.json();
        return data.data.translations[0].translatedText;
    } catch (error) {
        console.error('Error translating text:', error);
        return 'Translation failed';
    }
}

        async function startCameraAndMic() {
            try {

                mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                video.srcObject = mediaStream;


                recognition.start();


                startButton.disabled = true;
                stopButton.disabled = false;
            } catch (error) {
                console.error('Error accessing camera or microphone:', error);
                alert('Could not access the camera or microphone. Please check permissions.');
            }
        }

        function stopCameraAndMic() {
            if (mediaStream) {
                const tracks = mediaStream.getTracks();
                tracks.forEach(track => track.stop());

                video.srcObject = null;

                recognition.stop();

                startButton.disabled = false;
                stopButton.disabled = true;

                captionsDiv.textContent = 'Stopped listening.';
                translatedDiv.textContent = '';
            }
        }

        recognition.onresult = async (event) => {
            let transcript = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
                transcript += event.results[i][0].transcript;
            }

            captionsDiv.textContent = `Captions: ${transcript}`;

            const translatedText = await translateText(transcript, 'es');
            translatedDiv.textContent = `Translated: ${translatedText}`;
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            captionsDiv.textContent = 'Error: Could not process audio.';
        };
        recognition.onend = () => {
            captionsDiv.textContent = 'Stopped listening.';
        };

        startButton.addEventListener('click', startCameraAndMic);
        stopButton.addEventListener('click', stopCameraAndMic);
    </script>

</body>

</html>
